# Implementation Handoff: Convert Modal Embedder to Secure HTTP Endpoint

## ðŸ§© Overview

This task refactors the current `embed_query` function in `modal_embedder.py` into a secure `@modal.fastapi_endpoint(method="POST")` HTTP endpoint. This resolves production issues when calling Modal from Fly.io, which stem from unsupported usage of `modal.App.lookup(...).function(...).remote(...)` outside Modal's runtime.

The Fly backend will switch to calling this function via HTTPS using a POST request with a secret API key for authentication.

---

## âœ… Goals

- âœ… Refactor `embed_query(...)` into a secure HTTP endpoint
- âœ… Add API key validation
- âœ… Return 1024-dim embedding via JSON response
- âœ… Update `ModalEmbeddingService` class in `rag/modal_embedding_service.py` to make a POST request using `requests`
- âœ… Use `MODAL_EMBEDDER_API_KEY` for authentication
- âœ… Keep fallback local embedding unchanged for development mode

---

## ðŸ“‚ Files Modified

### 1. `modal_embedder/modal_embedder.py` âœ… COMPLETED
Refactored `embed_query` to:

```python
@app.function(
    image=image,
    secrets=[modal.Secret.from_name("MODAL_EMBEDDER_API_KEY")]
)
@modal.fastapi_endpoint(method="POST")
def embed_query(item: dict):
    """
    Convert a text query into a 1024-dimensional embedding vector via HTTP endpoint.
    
    Args:
        item: Dictionary containing:
            - "api_key": API key for authentication
            - "text": The text to embed
            
    Returns:
        Dictionary containing the embedding array
        
    Raises:
        Exception: If authentication fails or embedding generation fails
    """
    global model
    
    # Validate API key
    api_key = item.get("api_key")
    if api_key != os.environ["MODAL_EMBEDDER_API_KEY"]:
        raise Exception("Unauthorized")
    
    # Get text from request
    text = item.get("text")
    if not text:
        raise Exception("Missing 'text' field")
    
    if not isinstance(text, str):
        raise Exception("'text' must be a string")
    
    try:
        # Load model once and cache it for subsequent calls
        if model is None:
            logger.info("Loading model...")
            model = SentenceTransformer("BAAI/bge-large-en-v1.5")
            logger.info("Model loaded successfully")
        
        # Generate embedding with normalization enabled
        embedding = model.encode([text], normalize_embeddings=True)[0]
        
        logger.info(f"Generated embedding for text of length {len(text)}")
        return {"embedding": embedding.tolist()}
        
    except Exception as e:
        logger.error(f"Error generating embedding: {e}")
        raise Exception(f"Embedding generation failed: {e}")
```

### 2. `rag/modal_embedding_service.py` âœ… COMPLETED
Updated `_embed_via_modal(...)` method with:

```python
def _embed_via_modal(self, query: str, model_id: str) -> np.ndarray:
    """
    Embed query using Modal's HTTP endpoint.
    
    Args:
        query: The query string to embed
        model_id: Model identifier
        
    Returns:
        Normalized query embedding as numpy array
        
    Raises:
        RuntimeError: If HTTP request fails or embedding is invalid
    """
    url = "https://yogonwa--nobel-embedder-clean-slate-embed-query.modal.run"
    api_key = "6dab23095a3f8968074d7c9152d6707f3f7445bc145022f46fcceb0712864147"

    try:
        response = requests.post(
            url,
            json={"api_key": api_key, "text": query},
            timeout=10,
        )
        response.raise_for_status()
        data = response.json()
        embedding_list = data["embedding"]
        embedding = np.array(embedding_list, dtype=np.float32)

        # Validate embedding dimensions
        expected_dim = get_model_config(model_id)["embedding_dim"]
        if embedding.shape[0] != expected_dim:
            raise ValueError(
                f"Modal embedding dimension {embedding.shape[0]} "
                f"doesn't match expected {expected_dim} for model {model_id}"
            )

        log_with_context(
            logger,
            logging.DEBUG,
            "ModalEmbeddingService",
            "Modal embedding successful",
            {
                "query_length": len(query),
                "embedding_shape": embedding.shape,
                "model_id": model_id
            }
        )

        return embedding
    except Exception as e:
        logger.error(f"Failed HTTP embedding request: {e}")
        raise RuntimeError(f"Modal embedding service failed: {e}")
```

### 3. `modal_embedder/test.py` âœ… COMPLETED
Created test script to validate the HTTP endpoint:

```python
import requests
import json

# Test the new HTTP endpoint
url = "https://yogonwa--nobel-embedder-clean-slate-embed-query.modal.run"
api_key = "6dab23095a3f8968074d7c9152d6707f3f7445bc145022f46fcceb0712864147"

# Test query
query = "What did Toni Morrison say about justice?"

# Make the HTTP request
headers = {
    "Content-Type": "application/json"
}

data = {
    "api_key": api_key,
    "text": query
}

response = requests.post(url, json=data, headers=headers, timeout=30)

if response.status_code == 200:
    result = response.json()
    embedding = result["embedding"]
    print(f"âœ… Success! Embedding length: {len(embedding)}")
    # ... validation checks
```

---

## ðŸ” Secrets Setup âœ… COMPLETED

**Modal Secret (via CLI):**
```bash
modal secret set MODAL_EMBEDDER_API_KEY=6dab23095a3f8968074d7c9152d6707f3f7445bc145022f46fcceb0712864147
```

**API Key:** `6dab23095a3f8968074d7c9152d6707f3f7445bc145022f46fcceb0712864147`

---

## ðŸŒ Endpoint Details âœ… COMPLETED

**Endpoint URL:** `https://yogonwa--nobel-embedder-clean-slate-embed-query.modal.run`

**Request Format:**
```http
POST /
Content-Type: application/json

{
  "api_key": "6dab23095a3f8968074d7c9152d6707f3f7445bc145022f46fcceb0712864147",
  "text": "Your query here"
}
```

**Response Format:**
```json
{
  "embedding": [0.023, -0.011, 0.041, ...] // 1024 values
}
```

**Status Codes:**
- `200`: Success
- `400`: Bad request (missing text field)
- `401`: Unauthorized (invalid API key)
- `500`: Internal error

---

## âœ… Test Results âœ… COMPLETED

**Test Output:**
```
Testing POST to endpoint: https://yogonwa--nobel-embedder-clean-slate-embed-query.modal.run
Status Code: 200
âœ… Success!
Embedding length: 1024
First 5 values: [-0.023173874244093895, -0.011226102709770203, -0.01806841976940632, 0.04163658618927002, -0.061086151748895645]
Last 5 values: [0.053312476724386215, 0.0008303275681100786, 0.011637084186077118, 0.019241971895098686, -0.028682706877589226]
Embedding range: [-0.0877, 0.2089]
Max absolute value: 0.2089
âœ… Embedding appears to be normalized
```

**Validation:**
- âœ… HTTP endpoint responding correctly
- âœ… API key authentication working
- âœ… 1024-dimensional embeddings generated
- âœ… Embeddings properly normalized (max abs value â‰¤ 1.0)
- âœ… Fast response time (cold start handled by Modal)

---

## ðŸš€ Deployment Status âœ… COMPLETED

**Modal App:** `nobel-embedder-clean-slate`
**Status:** Deployed and functional
**URL:** https://modal.com/apps/yogonwa/main/deployed/nobel-embedder-clean-slate

---

## ðŸ“‹ Next Steps

1. âœ… **Modal endpoint deployed and tested**
2. âœ… **Client code updated to use HTTP requests**
3. âœ… **API key authentication implemented**
4. âœ… **Test script validates functionality**

**Ready for production use!** The Fly.io backend can now call the Modal embedding service via HTTP without the previous runtime compatibility issues.

---

## ðŸš¨ Performance Optimization Plan (Future Work)

### Problem Identified
The current HTTP-based embedder is experiencing **burst load performance issues** in production:

- **Burst Load**: Thematic queries trigger 5-10 parallel HTTP requests to Modal
- **Cold Start Storms**: Each request can trigger a new Modal container spin-up (~2s each)
- **Synchronous Blocking**: Python's default threading blocks requests from each other
- **Result**: Frontend timeouts on complex thematic queries

### Root Cause Analysis
When the thematic retriever expands queries like "justice and freedom", it generates multiple terms:
- "justice", "freedom", "injustice", "liberty", "equality", etc.
- Each term triggers a separate HTTP request to Modal
- Parallel requests cause cold start storms and timeouts

### Proposed Solutions

#### Phase 1: Immediate Fix (Sequential + Throttling) ðŸ”¥ PRIORITY
```python
# In modal_embedding_service.py
def _embed_multiple_via_modal(self, texts: List[str], model_id: str) -> List[np.ndarray]:
    """Embed multiple texts sequentially with throttling"""
    embeddings = []
    for i, text in enumerate(texts):
        if i > 0:
            time.sleep(0.25)  # Prevent cold start storms
        embedding = self._embed_via_modal(text, model_id)
        embeddings.append(embedding)
    return embeddings
```

**Benefits:**
- Prevents cold start storms
- Simple implementation
- Immediate performance improvement

#### Phase 2: Async Implementation (Next Sprint)
```python
import httpx
import asyncio

async def _embed_multiple_async(self, texts: List[str], model_id: str) -> List[np.ndarray]:
    """Async embedding with controlled concurrency"""
    async with httpx.AsyncClient() as client:
        semaphore = asyncio.Semaphore(3)  # Limit concurrent requests
        tasks = [self._embed_single_async(client, text, model_id, semaphore) for text in texts]
        return await asyncio.gather(*tasks)
```

**Benefits:**
- Controlled concurrency (3 requests max)
- Better resource utilization
- Maintains responsiveness

#### Phase 3: Batch Endpoint (Modal Side)
```python
@modal.fastapi_endpoint(method="POST")
def embed_batch(item: dict):
    """Batch embedding endpoint"""
    texts = item.get("texts", [])
    embeddings = model.encode(texts, normalize_embeddings=True)
    return {"embeddings": [emb.tolist() for emb in embeddings]}
```

**Benefits:**
- Single HTTP request for multiple texts
- Eliminates cold start overhead
- Maximum performance improvement

### Implementation Priority
1. **Phase 1 (Immediate)**: Sequential + throttling to fix production timeouts
2. **Phase 2 (Next Sprint)**: Async implementation for better UX
3. **Phase 3 (Future)**: Batch endpoint for optimal performance

### Files to Modify
- `rag/modal_embedding_service.py` - Add sequential/async methods
- `rag/thematic_retriever.py` - Update to use batch embedding
- `modal_embedder/modal_embedder.py` - Add batch endpoint (Phase 3)

---

## ðŸ”§ Troubleshooting

**If the endpoint stops working:**
1. Check Modal app status: `modal app list`
2. Redeploy if needed: `modal deploy modal_embedder.py`
3. Verify API key is still valid
4. Test with the provided test script

**If embeddings seem incorrect:**
1. Verify model is loading correctly (check logs)
2. Confirm embedding dimensions (should be 1024)
3. Check normalization (max abs value should be â‰¤ 1.0)

**If experiencing timeouts:**
1. Check for burst load patterns in logs
2. Implement Phase 1 sequential throttling
3. Monitor Modal container cold start times

---

## ðŸ“š References

- [Modal Web Endpoints Documentation](https://modal.com/docs/guide/webhooks)
- [FastAPI Endpoint Decorator](https://modal.com/docs/reference/modal.fastapi_endpoint)
- [Modal Secrets Management](https://modal.com/docs/guide/secrets)
